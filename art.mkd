
Краткий сравнительный обзор кодировок UTF-8 и UTF-16 в стандарте Unicode
------

<p align="right">И сказал Господь: вот, один народ, и один у всех язык; <BR>
и вот что начали они делать, и не отстанут они от того, что задумали делать; <BR> сойдем же и смешаем там язык их, так чтобы один не понимал речи другого. <BR>
Быт.11:7-8</p>


К счастью, человечество всё-таки смогло преодолеть некоторые барьеры, разделяющие его. Кроме этого спустя огромное количество времени люди научились не только устно делиться информацией на языках своих соседей по планете, но и хранить, передавать и воспроизводить её где угодно, куда угодно и как угодно, не взирая на многокилометровые расстояния.

С развитием информационных технологий требовалось представлять всё больше различных символов в удобном для обработки ЭВМ виде. Так появилась компьютерная кодировка для представления букв латинского алфавита, цифр, знаков препинания и некоторых других символов - ASCII (*англ. American Standard Code for Information Interchange*). Изначально закодированных символов было 128 (2^7 - т.к. байт равен 8 битам, последний бит использовался в качестве контроля чётности), но со временем диапазон был расширен до 256 символов из-за добавления “бита чётности”, который теперь являлся полноправной частью кодировки. Появившееся пространство было решено заполнить символами национального алфавита. Но как много на Земле народов, так же много и письменностей, которые являются одной из форм существования человеческого языка. Это значит, что в разных местах планеты символы 128-255 могли быть абсолютно разными, то есть не было единого стандарта, что при передаче и получении информации создавало бы множество проблем. 

Тогда был создан **Unicode** - стандарт кодирования символов (не следует путать с кодировками символов, с помощью которых реализуется стандарт). Применение этого стандарта позволяет закодировать огромное множество символов различного рода: начиная от привычных букв/цифр/знаков препинания или, например, иероглифов, заканчивая музыкальными символами и эмоджи. Для обозначения символов  в записи используется буква “U”, указывающая на стандарт, и шестнадцатеричная система счисления  для указания номера(позиции) конкретного символа (например, “U+024F”=”ɏ”).

Принятый стандарт внедрял общий язык кодировки, а значит не возникало ситуаций, когда один и тот же код являлся представлением разных символов, и вместе с тем, визуально одни и те же символы (например, русская и английская А) имели разный код, что не доставляет проблем при анализе текстов. Стандарт Unicode определяет то, что является кодом для символа, и то, как этот код будет представлен в памяти. Это представление в памяти и является *кодировкой*.

Существует несколько видов кодировок (т.е. форм представления - *англ. Unicode Transformation Format, UTF*) - различаются они по количеству байтов, используемых для кодирования каждого символа. Рассмотрим два из них, являющихся кодировками с переменной шириной (т.е. нет чёткого определения количества используемых байтов, по необходимости они берутся из диапазона):  UTF-8 и UTF-16.

**UTF-8** является самой распространенной кодировкой, она использует 1-4 байта. Первые 128 кодов содержат символы набора ASCII, то есть занимают 1 байт. Кодировку эффективно использовать в работе с латинскими буквами, цифрами 0-9 и общераспространенными знаками. Это не значит, что для работы с иероглифами или другими символами UTF-8 не подходит, т.к. UTF лишь форма представления символов, а не сам набор символов.

**UTF-16** использует 2 байта (16 бит) или 4 байта (32 бита), что эффективнее UTF-8, если требуется работать с необычными или специальными символами (ноты, иероглифы, пиктограммы). Большинство символов базовых языков можно представить 2 байтами.

**Итог**

Если предстоит работа без использования необычной письменности, лучше всего использовать UTF-8, т.к. это будет правильнее с точки зрения распределения памяти, кроме этого UTF-8 обратно совместима с программами и протоколами, использующими ASCII.
    Если же работать нужно со специфичными символами, возможно, стоит подумать об использовании кодировки UTF-16, но из-за большого разнообразия необходимо правильное обращение с составными символами (суррогатными парами), а это может стать препятствием на пути у новичка в работе с UTF-16.  

